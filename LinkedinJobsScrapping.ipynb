{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Linkedin Jobs Scrapping**\n",
    "In this project, I will conduct a web scraping data analysis to automatically extract job posting data from a job posting site. The goal is to be more prepared to land my first job as a intern in the data world. \n",
    "\n",
    "I want to see the location of the internship jobs and the requirements. Sadly, in Europe is not common to publish salary data, but I will also check the salaries of my -hopefully- first junior position. \n",
    "\n",
    "To achieve this, I will set up the environment, identify the job posting site, scrape the data, process, analyze, and visualize the data.\n",
    "\n",
    "Let's do it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Understanding the LinkedIn Jobs Search Page\n",
    "\n",
    "A quick inspection to the search page throws at us certain inconveniences:\n",
    "- The list of jobs are in individual cards with little information: company name, job name, location, and some extra info, like job id and link to the job post. So not everything is in one page.\n",
    "- It has **lazy load**. LinkedIn only loads the first 35 jobs at first. You need to scroll to the bottom of the page to load the next 25 jobs. \n",
    "- After 5 times lazyloading, a **'see more jobs'** button will pop up. \n",
    "\n",
    "Let's first solve the last two problems. **How can I load all the jobs in a search?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Scroll down and click with Selenium\n",
    "\n",
    "**Selenium** is a python library that automates browsers. So, basically, it will open a chrome tab and scroll down and click in the 'see more jobs' button for us.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Packages\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from selenium.webdriver.support.select import Select\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.service import Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code below opens a chrome window in the referenced url\n",
    "#Setting webdriver \n",
    "service = Service(executable_path=r'D:\\\\DATA\\\\Projects\\\\Linkedin-Jobs-Scrapping\\\\chromedriver-win64\\\\chromedriver.exe')\n",
    "driver = webdriver.Chrome(service=service)\n",
    "#The url we want to open. Later in the process we will make this url dynamic. \n",
    "url1 = 'https://www.linkedin.com/jobs/search/?keywords=Data&location=Spain&geoId=105646813&f_TPR=&f_E=1&position=1'\n",
    "driver.get(url1) #open the job search page\n",
    "driver.implicitly_wait(10) #for safety, wait 10 segs to give time to load completely "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "612"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Find number of jobs in the search\n",
    "\n",
    "n = driver.find_element(By.CLASS_NAME, 'results-context-header__job-count').text\n",
    "#Because LinkedIn writes '+17,700', we have to deal with any symbols to convert the number to an int.\n",
    "n = n.rstrip(\"+\")\n",
    "n = int(n.replace(\",\", \"\"))\n",
    "y=pd.to_numeric(n)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of jobs: 60\n",
      "number of jobs: 85\n",
      "number of jobs: 110\n",
      "number of jobs: 135\n",
      "number of jobs: 160\n",
      "number of jobs: 185\n",
      "number of jobs: 210\n",
      "number of jobs: 235\n",
      "number of jobs: 260\n",
      "number of jobs: 285\n",
      "number of jobs: 310\n",
      "number of jobs: 335\n",
      "number of jobs: 360\n",
      "number of jobs: 385\n",
      "number of jobs: 410\n",
      "number of jobs: 435\n",
      "number of jobs: 460\n",
      "number of jobs: 485\n",
      "number of jobs: 510\n",
      "number of jobs: 535\n",
      "number of jobs: 560\n",
      "number of jobs: 585\n",
      "number of jobs: 610\n",
      "number of jobs: 635\n",
      "number of jobs: 660\n",
      "number of jobs: 685\n",
      "number of jobs: 710\n"
     ]
    }
   ],
   "source": [
    "#Scrolling down and loading all jobs \n",
    "i = 0\n",
    "while i <= int((y+35+25)/25): \n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    i = i + 1\n",
    "    print('number of jobs:', 35+i*25)\n",
    "    \n",
    "    try:\n",
    "        driver.find_element(By.XPATH,'//*[@id=\"main-content\"]/section[2]/button').click()\n",
    "        time.sleep(1)\n",
    "            \n",
    "    except:\n",
    "        pass\n",
    "        time.sleep(2)\n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Step 3: Extracting the data from the job list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's initiate some lists\n",
    "CompanyName = []\n",
    "JobTitle= []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Emerald StayÂ® (A certified B Corp)'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testing the code\n",
    "driver.find_elements(By.CLASS_NAME, 'base-search-card__subtitle')[116].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Loop to go through all jobs and extract their data\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m job \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(y):\n\u001b[1;32m----> 3\u001b[0m     company \u001b[38;5;241m=\u001b[39m \u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_elements\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCLASS_NAME\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbase-search-card__subtitle\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mjob\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mtext\n\u001b[0;32m      4\u001b[0m     CompanyName\u001b[38;5;241m.\u001b[39mappend(company)\n\u001b[0;32m      6\u001b[0m CompanyName\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "#Loop to go through all jobs and extract their data\n",
    "for job in range(y):\n",
    "    company = driver.find_elements(By.CLASS_NAME, 'base-search-card__subtitle')[job].text\n",
    "    CompanyName.append(company)\n",
    "\n",
    "CompanyName"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I encountered a `IndexError: list index out of range` all the time. \n",
    "\n",
    "I checked more deeply how linkedIn loads their jobs and how the page look. After several attempts and searches, I figured out that linkedIn never shows the full list of available jobs.\n",
    "\n",
    "If your search job number is an inexact number (+17,000, for example), the page stops loading more jobs after several clicks on the button. \n",
    "\n",
    "If your search is an exact number, you can reach the 'You've viewed all jobs for this search' tag. But it is a bit deceitful. If you inspect their code, the last card is even referenced as the last number of your search. That is, if you had 617 jobs, you will see a div with the class: `data-row=\"610\"`. But actually they had been skipping numbers all the time. So out of a search of 600, they usually show half of them: 300.\n",
    "\n",
    "This could be good enough. But we are learning here. So I decided to try a different method. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2b: using Scrapy. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LJS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
